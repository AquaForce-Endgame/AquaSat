---
title: "A national, multi-decadal, water color and landsat dataset"
author: "Matthew Ross"
date: "7/2/2018"
output:
  html_document:
    toc: true
    toc_float:  true
  pdf_document:
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=F, warnings='hide'}
library(feather)
library(tidyverse)
library(knitr)
library(kableExtra)
library(pander)
library(LAGOSNE)
library(lubridate)
library(parallel)
library(foreach)
library(ggthemes)
library(sf)
library(USAboundaries)
library(scales)
library(broom)
library(ggpmisc)



knitr::opts_chunk$set(echo = FALSE,warning=F)
knitr::opts_knit$set(root.dir='../..')

lagos <- lagosne_load("1.087.1")

theme_set(theme_bw(base_size=14))
theme_update(
          panel.grid.major = element_line(color='transparent'),
        panel.grid.minor = element_blank()) 


```




# Introduction

Since the beginning of the Landsat missions, the remote sensing community has been interested in developing universal algorithms for extracting water quality information from remotely sensed images [@Lots of old papers]. While there has been significant success in the oceanic community towards universal algorithms for chlorophyll, sediment, and doc [cites], there is no inland water equivalent. Much of this discrepancy comes from the increased optical complexity of inland waters, which prevents the use of a more universal algorithm, but progress on inland waters is further impeded by  the lack of a shared dataset of overpasses and *in situ* concentration information. Here we create and share the largest such overpass dataset ever assembled. We also outline and share our approach to bringing three publicly available, free datasets to generate a high-graded analysis-ready dataset for remote sensors of water quality. While a specific universal algorithm may be an unattainable goal, we anticipate that this dataset will move us towards more universal approaches based on shared and equal access to overpass information. 


### Potential for transformative research with remote sensing of water quality

Despite the long-recognized potential, until recently, the general hydrology and limnology communities have not integrated data from remote sensing of inland waters into our research approach [Topp]. Instead, these communities have focused much of our research on Eulerian sampling schemes with sensors or people repeatedly sampling the same points in a river or lake [DoyleEnsign]. This research approach has generated a wealth of information on temporal variability in inland waters, but there has been less work looking at spatial variability in rivers, lakes, and estuaries. Remote estimates of water quality in these ecosystems would allow for rapid assessment of potential algae blooms, detection of high-sediment waters, and analysis of spatio-temporal variability [cites]. 

### Historic barriers

Serious citation of Topp, maybe none of this at all? 

### Modern solutions

With the profusion of publicly available *in situ* water quality datasets and the relatively easily-accessible satellite mission archive 

# Methods

## LANDSAT

```{r landsat table}
#Check clouds dataset to get the pers satellite scene count
# clouds <- read_feather('2_rsdata/out/clouds.feather') %>%
#   mutate(sat=str_split_fixed(LANDSAT_ID,'_',2)[,1])
# 
# table(clouds$sat)


landsat <- tibble(Satellite = c('5','7','8'),
                  Years = c('1984-2012','1999-2018','2013-2018'),
                  `Available images` = rev(c('58,585','188,781','192,688')))
                  
knitr::kable(landsat)
```


## WQP Parameters

```{r}



```

## Rivers, Lakes, and Estuaries/Deltas

## Water Quality Portal 

### data pull and parameters therein

### Data harmonization approach and link to code output

## LAGOSNE

### Describe Lagos daasets

### In Situ data unification

## Joining landsat and water quality portal

### Google Earth Engine

### How we selected sites (pekel occurence)

### Diagram of joining procedures and counts of observations dropped

## Data quality flagging

### Not sure what to put here or if we should have this section


# Results

For LAGOSNE data see [here](https://lagoslakes.org/the-lagos-database/)

## Dataset description

```{r , echo=FALSE, fig.cap="Dataset generation", out.width = '100%'}
knitr::include_graphics(paste0(getwd(),"/9_report/src/Watersat_Drop_flow.png"))
```



```{r data read in}
wqp.all <- read_feather('1_wqdata/out/wqp_lagos_unity.feather')



full.inv <- read_feather('1_wqdata/out/wqp_inventory.feather') %>%
  select(SiteID = MonitoringLocationIdentifier,type=ResolvedMonitoringLocationTypeName) %>%
  distinct() %>%
  mutate(type = ifelse(grepl('Lake',type),'Lake',type))

lagos.locus <- lagos$locus %>%
  distinct(lagoslakeid,.keep_all = T)




wqp.inv <- wqp.all %>%
  select(SiteID,date_unity,tss,doc,chl_a,secchi)  %>%
  left_join(full.inv,by=c('SiteID')) %>%
  #Make sure all lagos sites have the lake id tag
  mutate(type = ifelse(is.na(type),'Lake',type)) %>%
  filter(type != 'Facility')



count.kable <- function(df){
  df %>% 
  gather(key=Parameter,value=value,-SiteID,-date_unity,-type) %>%
  filter(!is.na(value)) %>%
  group_by(Parameter,type) %>%
  summarize(count=n()) %>% 
  arrange(type,Parameter) %>%
  spread(key=Parameter,value=count) %>%
  ungroup() %>%
  add_row(type='Total',
          chl_a=sum(.$chl_a),
          doc=sum(.$doc),
          secchi=sum(.$secchi),
          tss=sum(.$tss)) %>%
  kable(.,format.args = list(big.mark = ","))
}

### Landsat visible sites including lagos

load('3_rswqjoin/data/out/sr_insitu.RData')


sr.type <- sr.clean %>%
  left_join(full.inv,by='SiteID') %>%
  mutate(type=ifelse(is.na(type),'Lake',type)) %>%
  filter(type != 'Facility') %>%
  ungroup()



```



### Map

```{r,fig.width=8,fig.height=10, fig.cap='Distribution of observations across the conterminous USA. The data is split by observation type, where total represents an overpass for any of the four primary parameters'}

# Get a total number of counts by site and lat long.
# We round lat long to prevent plotting 80,000 points 
# But the counts are still representative of the data distribution
counts.by.type <- sr.type %>%
  mutate(roundlat=round(lat,1),
         roundlong=round(long,1)) %>%
  select(SiteID,roundlat,roundlong,chl_a,tss,doc,secchi,type) %>%
  gather(key=parameter,value=value,-SiteID,-roundlat,-roundlong,-type) %>%
  filter(!is.na(value)) %>%
  group_by(type,parameter,roundlat,roundlong) %>%
  summarize(overpasses = n()) %>%
  ungroup() 


#Get total counts
total.counts <- sr.type %>%
  mutate(roundlat=round(lat,1),
         roundlong=round(long,1)) %>%
  group_by(type,roundlat,roundlong) %>%
  summarize(overpasses = n()) %>%
  ungroup() %>%
  mutate(parameter='total') %>%
  select(names(counts.by.type))

#Combine datasets for plotting with a single ggplot call
all.counts <- rbind(counts.by.type,total.counts) %>%
  #ORder the data how I want it
  mutate(parameter=factor(parameter,levels=c('secchi','chl_a','tss','doc','total'))) %>%
  arrange(desc(overpasses))

#Recast us_states to epsg 2163 and remove states that make plotting harder
usa <- us_states() %>%
  st_transform(.,2163) %>%
  filter(!state_name %in% c('Alaska','Hawaii','Puerto Rico'))

#Convert the all.count dataset to an sf object
total.sf <- st_as_sf(all.counts,coords=c('roundlong','roundlat'),crs=4326) %>%
  st_transform(2163)

#Subset the total dataset to only the usa. This intuitive data[subset,] is 
#one of my favorite spatial R things!
total.sf.usa <- total.sf[usa,] 


#Functino to turn geometry into lat longs for stat_hex
sfc_as_cols <- function(x, names = c("x","y")) {
  stopifnot(inherits(x,"sf") && inherits(sf::st_geometry(x),"sfc_POINT"))
  ret <- do.call(rbind,sf::st_geometry(x))
  ret <- tibble::as_tibble(ret)
  stopifnot(length(names) == ncol(ret))
  ret <- setNames(ret,names)
  dplyr::bind_cols(x,ret)
}

total.sf.lat <- sfc_as_cols(total.sf.usa)
#Map with hex plots summing over the number of overpasses. 
ggplot() + 
  geom_sf(data=usa,fill='white') + 
  stat_summary_hex(data=total.sf.lat,
          aes(x,y,z=overpasses),
          bins=50,fun=sum)  +
  facet_wrap(~parameter,ncol=2) + 
  theme(legend.position = c(.75,.15)) + 
  theme(panel.grid.major = element_line(color='transparent'),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  scale_fill_gradient2(low='blue',mid='gray50',high='red',midpoint=log10(100),
                       breaks=c(1,10,100,1000,10000),
                       labels=c('1','10','100','1,000','10,000'),
                       name='Matchups',trans='log10') +
  ylab('') + 
  xlab('')

```

### Distribution of observations per site

```{r,fig.height=6,fig.width=8}

#Set colors by type
type.cols <- c('#a6cee3','#33a02c','#1f78b4')

#get site counts 
sr.counts <- sr.type %>%
  select(tss,secchi,chl_a,doc,SiteID,date_unity,type,lat,long) %>% 
  gather(key=parameter,value=value,-SiteID,-date_unity,-type,-lat,-long) %>%
  filter(!is.na(value)) %>%
  mutate(type=factor(type,levels=c('Stream','Estuary','Lake'))) %>%
  group_by(SiteID,parameter,type) %>%
  summarize(count=n()) %>%
  ungroup() %>%
  filter(count != 0)

#Plot
ggplot(sr.counts,aes(x=count,fill=type)) +
  geom_histogram(bins=25) + 
  facet_wrap(~parameter,scales='free_y') +
  scale_x_log10(breaks=c(1,10,100,1000)) + 
  xlab('Number of observations at site') +
  ylab('Number of sites with X observations') + 
  scale_fill_manual(name='',values=type.cols)+ 
  theme_few(base_size=14) + 
  theme(legend.position=c(.85,.8)) 

```


### Observations over time

```{r,fig.width=8,fig.height=3.5}

#Choose colors for each parameter
parameter.cols <- c('gray40','#2e8b57','#e8a766','#583a1c')

#Get yearly counts for each parameter for overpasses
matchup.yearly.counts <- sr.type %>%
  mutate(year = year(date_unity)) %>%
  select(SiteID,year,chl_a,tss,doc,secchi,type) %>%
  gather(key=parameter,value=value,-SiteID,-year,-type)  %>%
  filter(!is.na(value)) %>%
  group_by(parameter,year) %>%
  summarize(count=n()) %>%
  mutate(datasource='Landsat matchups')

#Same for full in situ dataset
wqp.yearly.counts <- wqp.inv %>%
  mutate(year = year(date_unity)) %>%
  select(SiteID,year,chl_a,tss,doc,secchi,type) %>%
  gather(key=parameter,value=value,-SiteID,-year,-type)  %>%
  filter(!is.na(value)) %>%
  group_by(parameter,year) %>%
  summarize(count=n()) %>%
  filter(year < 2019 & year > 1984) %>%
  mutate(datasource='LAGOSNE + WQP') 

#Bind datasets together
yearly.counts.all <- rbind(matchup.yearly.counts,wqp.yearly.counts)

#Plot side by side
yearly.counts.all %>%
  ungroup() %>%
    mutate(parameter=factor(parameter,levels=c('secchi','chl_a','tss','doc'))) %>%
  ggplot(., aes(x=year,y=count,fill=parameter)) + 
           geom_bar(position='stack',stat='identity') + 
  scale_fill_manual(values=parameter.cols,name='') + 
  theme(legend.position=c(0.65,0.7),
        axis.text.y=element_text(angle=90,hjust=0.5)) + 
  facet_wrap(~datasource) + 
  ylab('Count') + 
  xlab('Year') +
  scale_y_continuous(breaks=c(0,100000,200000,300000), 
                     labels=c(0,'100,000','200,000','300,000')) 
```


## Variation captured by the datasets

### Distributions of in situ vs matchup datasets

```{r,fig.height=7,fig.width=7}

param.units <- tibble(parameter = c('chl_a','doc','secchi','tss'),
                      param_units = c('chl_a (ug/L)',
                                      'doc (mg/L)',
                                      'secchi (m)',
                                      'tss (mg/L)'))

#Make a function to prepare datasets for plotting. Limit datasets to a range of greater than 10^-4
hist.data.prep <- function(x){
  out <- x  %>%
  select(SiteID,date_unity,type,tss,chl_a,secchi,doc) %>%
  gather(key=parameter,value=value,-SiteID,-date_unity,-type) %>%
  filter(!is.na(value)) %>%
  filter(value > 0.0001) %>%
  left_join(param.units,by='parameter')
}

matchup.hist <- hist.data.prep(sr.type) %>%
  mutate(Dataset='Landsat matchups')
insitu.hist <- hist.data.prep(wqp.inv) %>%
  mutate(Dataset='LAGOSNE + WQP')


# Cut the data into quantiles
q.cut.percents = c(0,0.05,.25,.5,0.75,.95,1)
q.cut.labels = c('<5%','5-25%','25-50%','50-75%','75-95%','>95%')
#Setup a colorpalette
quantile.colors <- RColorBrewer::brewer.pal(length(q.cut.percents)+2,'GnBu')[-c(1:2)]


#Matchup quantiles
matchup.quantiles <-  matchup.hist %>%
  group_by(param_units) %>%
  filter(value > 0 & !is.na(value)) %>%
  mutate(q.values = cut(value,quantile(value,q.cut.percents),
                        labels=q.cut.labels)) %>%
  group_by(param_units,q.values) %>%
  summarize(cut.max=max(value,na.rm=T),
            cut.min=min(value,na.rm=T),
            count=n()) %>%
  filter(!is.na(q.values))



ggplot() +
  geom_rect(data=matchup.quantiles,
            aes(xmin=cut.min,
                xmax=cut.max,
                ymin=1,
                ymax=10^11,
                fill=q.values),
            color=NA) +
  facet_wrap(~param_units,scales='free') +
  scale_x_log10(breaks=trans_breaks("log10", function(x) 10^x),
              labels = trans_format("log10", math_format(10^.x))) +
  scale_y_log10(breaks=trans_breaks("log10", function(x) 10^x),
              labels = trans_format("log10", math_format(10^.x))) +
  geom_histogram(data=rbind(matchup.hist,insitu.hist),
       aes(x=value,color=Dataset),
       fill='gray50',
       bins=50,
       size=1) + 
  scale_fill_manual(values=quantile.colors,name='Quantiles') +
  scale_color_manual(values=c('black','red3'),name='Dataset') + 
  theme(legend.position = 'top',legend.direction = 'horizontal',legend.box='vertical') +
  ylab('Count') + 
  xlab('Depth or Concentration') +
  guides(fill=guide_legend(byrow=T))



```

### Observations lost 

For both DOC and TSS our matchup dataset is missing the long tail of data in the in situ dataset. What kind of sites were dropped to create this discrepancy?
They are basically all streams.
```{r}
#For doc the dropoff of data is above 10^2 and tss is 10^4.5

missing.matchups <- insitu.hist %>%
  filter(parameter %in% c('doc','tss')) %>%
  filter(parameter == 'doc' & value > 10^2 |
        parameter == 'tss' & value > 10^4.5)

table(missing.matchups$type)

```


### Spectral variation

```{r, fig.width=8,fig.height=6}
#Create some simple quality filters and a long dataset with bands arranged in a long format. 
sr.long.median <-  sr.type %>%
  mutate(ndvi=(nir-red)/(nir+red)) %>%
  filter(ndvi < 0.6) %>%
  filter(swir2 < 600) %>%
  filter(clouds < 40) %>%
  filter(pixelCount > 9) %>%
  #For the library plots lets only keep sameday matchups
  select(SiteID,date_unity,lat,long,date,type,blue,green,red,nir,swir1,swir2,tss,chl_a,doc,secchi) %>%
  gather(key=band,value=refl,-SiteID,-date,-date_unity,-type,-tss,-chl_a,-doc,-secchi,-lat,-long) %>%
  mutate(band=factor(band,levels=c('blue','green','red','nir','swir1','swir2'))) %>%
  mutate(type=factor(type,levels=c('Stream','Estuary','Lake'))) %>%
  filter(refl > 0 )


sr.long.same <- sr.long.median %>%
  filter(date == as.Date(date_unity)) %>%
  mutate(tss.bin=cut(tss,
                     breaks=c(min(tss,na.rm=T),10,50,max(tss,na.rm=T)),
                     labels=c('< 10 mg/L','10-50 mg/L','>50 mg/L'))) %>%
  mutate(tss.keep=tss) %>%
  gather(key=parameter,value=value,-SiteID,-date_unity,
         -date,-band,-refl,-type,-tss.bin,-lat,-long,-tss.keep) %>%
  group_by(parameter) %>%
  filter(value > 0.001) %>%
  mutate(quintiles=cut(value,
                       quantile((value),q.cut.percents),
                       labels=q.cut.labels)) %>%
  mutate(quintile.cut.value = cut((value),q.cut.percents)) %>%
  ungroup() %>%
  filter(!is.na(quintiles)) %>%
  mutate(quintiles=factor(quintiles,levels=q.cut.labels))

#Plot data by quantile and band
sr.long.same %>%
  ggplot(.,aes(x=band,y=refl,fill=quintiles)) +
  ylim(0,1500) +
  geom_boxplot(outlier.shape=NA,position='dodge') +
  facet_wrap(~parameter) + 
  scale_fill_manual(values=quantile.colors,name='') + 
  theme(legend.position=c(0.25,0.91),legend.direction = 'horizontal') +
  ylab('Surface reflectance') +
  xlab('Band')+
  guides(fill=guide_legend(byrow=T))
```

## Partitioning variation by sediment concentration and region

### TSS covarying with other constituents

```{r,fig.width=8,fig.height=4}


sr.breakdown <- sr.long.same %>%
  filter(!is.na(tss.bin)) %>%
    left_join(param.units,by='parameter') %>%
  filter(tss.keep > 10^-2, tss.keep < 10^3.5) 



sr.bin.wide <- sr.breakdown %>%
  spread(key=band,value=refl) 

wide.tss <- sr.bin.wide %>%
  spread(key=parameter,value=value)


ggplot(sr.bin.wide %>%
         filter(parameter != 'tss'),aes(x=tss.keep,y=value)) + 
  geom_hex(bins=40) + 
  stat_smooth(method='lm') + 
  facet_wrap(~param_units,scales='free_y',nrow=1) + 
  scale_y_log10() + 
  scale_x_log10() + 
  xlab('TSS (mg/L)') + 
  ylab('Concentration') + 
  stat_poly_eq(aes(label = paste(..adj.rr.label.., sep = "~~~")), 
               label.x.npc = "left", label.y.npc = 0.9,
               formula = formula, parse = TRUE, size = 3)

```


### TSS impacts reflectance relationships for all constituent band combinations
```{r,fig.height=8,fig.width=10}
band.mod <- function(df) {
  mod <- lm(log10(value)~log10(refl),data=df)
}

band.sed.mod <- function(df) {
  mod <- lm(log10(value) ~ log10(refl) * log10(tss.keep),data=df)
}


sr.bin.mod <- sr.breakdown %>%
  group_by(parameter,band) %>%
  nest() %>%
  mutate(band.mods = map(data,band.mod)) %>%
  mutate(band.sed.mods=map(data,band.sed.mod)) %>%
  mutate(tidy.band.mod= map(band.mods,glance),
         tidy.band.sed.mod=map(band.sed.mods,glance))


mod.results <- unnest(sr.bin.mod,tidy.band.mod)  %>%
  select(parameter,band,adj.r.squared) %>%
  mutate(type='Band Only') %>%
  rbind(unnest(sr.bin.mod,tidy.band.sed.mod) %>%
          select(parameter,band,adj.r.squared) %>%
  mutate(type='Band and TSS')) %>%
  mutate(r2 = paste('R^2 ==',round(adj.r.squared,2))) %>%
  mutate(x=150,
         y=10^4.2,
         x=ifelse(type == 'Band and TSS',1500,x)) %>%
  filter(!band %in% c('swir1','swir2'))



ggplot() +
  geom_point(data=sr.breakdown %>%
         arrange(date_unity) %>%
         filter(tss.keep > .01,
                tss.keep < 5000,
                !band %in% c('swir1','swir2')),
       aes(x=refl,y=value,color=(tss.keep)),
       shape=1,size=.8) +
  scale_y_log10() + 
  scale_x_log10(limits=c(50,5000)) + 
  facet_grid(parameter ~ band) + 
  scale_color_gradient2_tableau(palette = "Red-Blue", space = "rgb",
                                na.value = "grey50", guide = "colourbar",name='Log TSS',trans='log10',
                                breaks=c(0.1,1,10,100,1000),
                                labels=c('0.1','1','10','100','1,000')) + 
  geom_text(data=mod.results %>%
              filter(type == 'Band Only'),
            aes(x,y,label=r2),size=3,parse=T) +
  geom_text(data=mod.results %>%
              filter(type == 'Band and TSS'),
            aes(x,y,label=r2),size=3,parse=T,color='tan4')

```


### Variation by ecoregion 
```{r,fig.width=12,fig.height=8}

ecoreg <- st_read('9_report/in/us_eco_l3/us_eco_l3.shp') %>%
    st_simplify(dTolerance=500) %>%
  mutate(NA_L2NAME=as.character(NA_L2NAME)) %>%
  mutate(NA_L2NAME = ifelse(NA_L2NAME=='MISSISSIPPI ALLUVIAL AND SOUTHEAST USA COASTAL PLAINS','MISSISSIPPI ALLUVIAL',NA_L2NAME)) %>%
  group_by(NA_L2NAME) %>% 
  summarise(m = sum(Shape_Area)) %>% 
  st_transform(2163) 

same.sf <- st_as_sf(sr.long.same %>% 
                         distinct(SiteID,long,lat),
                       coords=c('long','lat'),crs=4326) %>%
  st_transform(2163)

eco.sf <- st_join(same.sf,ecoreg) %>%
  filter(!is.na(NA_L2NAME)) %>%
  as.data.frame() %>%
  as_tibble()

sr.long.sf <- left_join(sr.long.same,eco.sf,by=c('SiteID')) %>%
  filter(!is.na(NA_L2NAME)) %>%
  group_by(NA_L2NAME) %>%
  mutate(L2_count = n()) %>%
  mutate(Region2 = paste(NA_L2NAME,L2_count))  

ecoreg.counts <- left_join(ecoreg,sr.long.sf %>%
                             distinct(Region2,NA_L2NAME,L2_count),
                           by='NA_L2NAME') 
ggplot() + 
  geom_sf(data=ecoreg.counts,aes(fill=L2_count)) +
  scale_fill_gradient2(low='blue',mid='gray50',high='red',midpoint=log10(5000),
                       breaks=c(10,100,1000,10000,100000),
                       labels=c('10','100','1,000','10,000','100,000'),
                       name='Matchups',trans='log10')


```



### Variation in TSS by ecoregion
```{r,fig.width=12,fig.height=8}

sr.sf.breakdown <- sr.long.sf %>%
    left_join(param.units,by='parameter') %>%
  filter(tss.keep > 10^-2, tss.keep < 10^3.5)  %>%
  filter(L2_count > 50000)

ggplot(sr.sf.breakdown %>%
         filter(parameter != 'tss',
                !is.na(tss.bin)),
       aes(x=tss.keep,y=value)) + 
  geom_hex(bins=40) + 
  stat_smooth(method='lm') + 
  facet_grid(param_units~Region2) + 
  scale_y_log10() + 
  scale_x_log10() + 
  xlab('TSS (mg/L)') + 
  ylab('Concentration')
```


### Variation in spectral response by ecoregion
```{r,fig.width=14,fig.height=10}
ggplot(sr.sf.breakdown %>%
         arrange(date_unity) %>%
         filter(!band %in% c('swir1','swir2')),aes(x=refl,y=value,color=Region2)) +
  geom_point(shape=1,size=.5) +
  scale_x_log10() + 
  scale_y_log10() + 
  facet_grid(parameter~band) + 
  stat_smooth(method='lm',se=F,fullrange=T) +
  scale_color_few()



```




# Supplementary

## Ecoregion models

```{r, eval=F}
sr.sf.wide <- spread(sr.long.sf,key=band,value=refl) 

tss.wide <- sr.sf.wide %>%
  filter(parameter == 'tss') %>%
  filter_at(.vars=c('red','blue','green','swir2','nir'),all_vars(. < 1500 & . > 0)) %>%
  mutate(hue=rgb2hsv(r=red,b=blue,g=green,maxColorValue = 1500)[1,],
         brightness=rgb2hsv(r=red,b=blue,g=green,maxColorValue = 1500)[3,]) %>%
  rename(tss=value) %>%
  mutate(l1 = droplevels(l1))  %>%
  filter(hue > 0)


mymod <- function(x){
  mod <- lm(log10(tss) ~ log10(hue)*log10(nir)+log10(brightness),data=x)
}

summary(tss.wide)
library(broom)
library(Metrics)

eco.mods <- tss.wide %>%
  group_by(l1,type) %>%
  nest() %>%
  mutate(mods=map(data,mymod)) %>%
  mutate(pred = map2(mods,data,predict)) %>%
  unnest(data,pred)  %>%
  mutate(pred=10^pred) %>%
  group_by(l1,type) %>%
  summarize(rmse=rmse(tss,pred),
            count=n(),
            mdae=mae(tss,pred),
            mape=mape(tss,pred),
            median=median(tss)) %>%
  arrange(mdae) %>%
  filter(count > 20)

(eco.mods)
```


```{r, eval=F}
big.rivers <- st_read('9_report/in/ne_10m_rivers_lake_centerlines/ne_10m_rivers_lake_centerlines.shp') %>%
  st_transform(2163) 


usa <- us_states() %>%
  st_transform(2163)

usa.rivers <- big.rivers[usa,] %>%
  st_buffer(1000)


sr.same.sf <- sr.type  %>%
  mutate(ndvi=(nir-red)/(nir+red)) %>%
  mutate(timediff=date_unity-time) %>%
  filter(ndvi < 0.6) %>%
  filter(swir2 < 600) %>%
  filter(clouds < 30) %>%
  filter(pixelCount > 6) %>%
  filter(type=='Stream') %>%
  filter(tss > 0) %>%
  st_as_sf(.,coords=c('long','lat'),crs=4326) %>%
  st_transform(2163)  %>%
  filter_at(.vars=c('red','blue','green','swir2','nir'),all_vars(. < 1500 & . > 0)) %>%
  mutate(hue=rgb2hsv(r=red,b=blue,g=green,maxColorValue = 1500)[1,],
         brightness=rgb2hsv(r=red,b=blue,g=green,maxColorValue = 1500)[3,])




big.river.join <- st_join(sr.same.sf,usa.rivers) %>%
  filter(!is.na(name_en)) %>%
  mutate(name=as.character(name_en)) %>%
  group_by(name) %>%
  mutate(count=n()) %>%
  filter(count > 20)


mymod <- function(x){
  mod <- lm(log10(tss) ~ log10(hue)*log10(nir)+log10(brightness),data=x)
}


library(broom)
library(Metrics)

big.river.mods <- big.river.join %>%
  as.data.frame() %>%
  as_tibble() %>%
  select(name,SiteID,blue,date_unity,green,nir,red,swir1,swir2,tss,hue,brightness,clouds) %>%
  group_by(name) %>%
  nest() %>%
  mutate(mods=map(data,mymod)) %>%
  mutate(pred = map2(mods,data,predict)) %>%
  unnest(data,pred)  %>%
  mutate(pred=10^pred) %>%
  group_by(name) %>%
  summarize(rmse=rmse(tss,pred),
            count=n(),
            mdae=mae(tss,pred),
            mape=mape(tss,pred)) %>%
  arrange(mdae)
  #mutate(glance=map(mods,glance)) %>%
  #unnest(glance) %>%
  #arrange(desc(rmse))



print(big.river.mods[1:10,])
```


### Mississippi Basin Example
```{r eval=F}
miss <- big.river.join %>%
  filter(name == 'Mississippi') %>%
  as.data.frame(.) %>%
  as_tibble(.) %>%
  filter(hue > 0.05) %>%
  filter(tss > 2)

ggplot(miss,aes(x=brightness,y=tss,color=log10(nir))) +
  geom_point() +
  scale_x_log10() +
  scale_y_log10()  

```




### Spectral medians captured at sample sites

```{r,eval=F}

band.cols <- c('blue2','green3','red','red3','gray50','black')

sr.long.median <-  sr.type %>%
  select(SiteID,date_unity,date,type,blue,green,red,nir,swir1,swir2,tss,chl_a,doc,secchi) %>%
  gather(key=band,value=refl,-SiteID,-date,-date_unity,-type,-tss,-chl_a,-doc,-secchi) %>%
  mutate(band=factor(band,levels=c('blue','green','red','nir','swir1','swir2'))) %>%
  mutate(type=factor(type,levels=c('Stream','Estuary','Lake'))) %>%
  filter(refl > 0 )


sr.long.median %>%
  ggplot(.,aes(refl,color=band)) + 
  geom_line(stat='density',size=0.9) +
  facet_wrap(~type,nrow=3) + 
  scale_x_log10()+ 
  scale_color_manual(values=band.cols,name='')   

```



### Spectral variation captured by our circles 
```{r, eval=F, fig.width=7}
sr.long.sd <- sr.type %>%
  mutate(blue_cv = blue_sd/blue,
         green_cv= green_sd/green,
         red_cv=red_sd/red,
         nir_cv=nir_sd/nir,
         swir1_cv=swir1_sd/swir1,
         swir2_cv=swir2_sd/swir2) %>%
  #For the library plots lets only keep sameday matchups
  select(SiteID,date_unity,type,blue_cv,green_cv,red_cv,nir_cv,swir1_cv,swir2_cv) %>%
  gather(key=band,value=cv,-SiteID,-date_unity,-type) %>%
  mutate(band=factor(band,levels=c('blue_cv','green_cv','red_cv','nir_cv','swir1_cv','swir2_cv'))) %>%
  mutate(type=factor(type,levels=c('Stream','Estuary','Lake'))) 



sr.long.sd %>%
  ggplot(.,aes(cv,color=band)) + 
  geom_line(stat='density',size=0.9) + 
  facet_wrap(~type,nrow=3) + 
  scale_x_log10(breaks=c(0.01,0.1,1,10)) + 
  scale_color_manual(values=band.cols,name='')   




```


### Lots of PCA analyses

```{r,eval=F}


no.zero.sameday <- sr.type %>%
  filter(date==as.Date(date_unity)) %>%
  filter_at(vars(c('red','blue','green','nir','swir1','swir2')),all_vars(. > 0)) %>%
  mutate(ndvi=(nir-red)/(nir+red)) %>%
  filter(ndvi < 0.6) %>%
  filter(swir2 < 400) %>%
  filter(clouds < 30) %>%
  filter(pixelCount > 6)


pca1 <- no.zero.sameday %>%
  mutate(rg=red/green,
         rb=red/blue,
         nr=nir/red) %>%
  mutate_at(.vars=vars(c('red','blue','green','nir','swir1')),funs(round(log10(.),2))) %>%
  select(rg,rb,nr,red,blue,green,nir,swir1,ndvi) %>%
  prcomp(.,scale=T) 

clusters <- as_tibble(pca1$x) %>%
  select(PC1,PC2,PC3,PC4) %>%
  kmeans(.,4)

summary(pca1)
no.zero.clusters <-  no.zero.sameday %>%
  mutate(cluster=as.character(clusters$cluster)) 

simultaneous.wide <- no.zero.clusters %>%
  filter_at(vars(c('secchi','chl_a','tss','doc')),all_vars(. > 0))

simultaneous.sf <- simultaneous.wide %>%
  st_as_sf(.,coords=c('long','lat'),crs=4326) %>%
  st_transform(2163)

simultaneous.sf <- simultaneous.sf[usa,]


no.zero.clusters %>%
  select(SiteID,date_unity,cluster,tss,chl_a,secchi,doc) %>%
  gather(key=parameter,value=value,-SiteID,-date_unity,-cluster) %>%  ggplot(.,aes(cluster,value)) +
  geom_boxplot(outlier.shape=NA) + 
  facet_wrap(~parameter)+ 
  ylim(0,50)




no.zero.clusters %>%
  group_by(cluster) %>%
  summarize(chl_a=median(chl_a,na.rm=T),
            doc=median(doc,na.rm=T),
            tss=median(tss,na.rm=T),
            secchi=median(secchi,na.rm=T)) 

```


### Clusters mapped onto tss doc plot. 
```{r,eval=F}
ggplot() +
  geom_point(data=simultaneous.wide,aes(x=tss,y=doc,color=cluster),shape=1) + 
  scale_x_log10() + 
  scale_y_log10()


```

```{r, eval=F, fig.width=8,fig.height=6}
library(ggpubr)
width.boxplotter <- function(param) {
  sr.long.same %>%
  filter(parameter == param) %>%
  group_by(parameter) %>%
  ggplot(.,aes(x=band,y=refl,fill=quintiles)) +
  ylim(0,1500) +
  geom_boxplot(outlier.shape=NA,position='dodge',varwidth=T) +
  facet_wrap(~parameter) + 
  scale_fill_manual(values=quantile.colors,name='',guide=F)
}
png(filename='9_report/figures/quantilebins_byobs.png',width=8,height=6,units='in',res=250)

chl_a.g <- width.boxplotter('chl_a') +
  scale_fill_manual(values=quantile.colors,name='') + 
  theme(legend.position = c(.25,0.91),legend.direction = 'horizontal') 

doc.g <- width.boxplotter('doc')


secchi.g <- width.boxplotter('secchi')
tss.g <- width.boxplotter('tss')

ggarrange(chl_a.g + rremove('xlab'),doc.g,secchi.g,tss.g,
         ncol=2,nrow=2)

dev.off()


```


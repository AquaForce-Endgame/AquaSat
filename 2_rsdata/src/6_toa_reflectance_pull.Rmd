---
title: "3_Flat_Overpasses"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(feather)
library(knitr)
library(purrr)
library(reticulate)
library(googledrive)
opts_knit$set(root.dir='../..')

```
```{r}

repl_python()
import os
toapy = r.toa_existing
#Identify upload and download directories.

DLdir = '2_rsdata_out/toa_matchups/'

ULdir = '2_rsdata/out/SplitWide/'

#Generate file lists for both
filesDown = r.toa_existing['name']
filesUp = os.listdir(ULdir) 

#Remove hidden formatting file in directory and any file names in filesUp that are already in files down.
filesUp  = filter(lambda x: x  != '.DS_Store', filesUp)
filesDown = [i.replace(".csv", ".feather") for i in filesDown]

filesUpFlt = [x for x in filesUp if x not in filesDown]
      
      import ee
print 'hello world'
exit
```

This script takes the shouldered, filtered in situ water quality dataset pulled from the Water Quality Portal/LAGOS and extracts associated top of atmosphere reflectance values from Google Earth Engine.  The pulled reflectance values are the median pixel value of pixels with 80% water occurence (according to Pekel) within 120m of the provided lat/long of the in situ sample identified in the water quality dataset.

## The engine path identified with an authorized google earth engine account may need updating from one individual computer to another.


```{r}

###Download the split wqp/lagos data to send up to GGE.  This is easier in R than python. Also create a list of existing reflectance csv's to filter what's sent up.

library(googledrive)
splits <- drive_ls('watersat/2_rsdata/out/SplitWide/')


if(length(list.files('2_rsdata/out/SplitWide')) < 546){
  for(i in 1:nrow(splits)) {
    path = paste0(getwd(),'/2_rsdata/out/SplitWide/', x$name[i])
    drive_download(as_id(splits$id[i]),
                   path=path, overwrite = TRUE)
  }
}

filesDownR <- drive_ls("watersat/2_rsdata/out/toa_matchups/") %>% 
  select(name)

```



```{r}

##repl_python basically starts a python bash window within your R chunk.  This can be used to actually interact with earth engine.
repl_python()
import time
import ee
import os
import feather
execfile('2_rsdata/src/5a_6a_GEE_pull_functions.py')

ee.Initialize()

#Source necessary functions.

#Load in Pekel water occurance Layer and Landsat Collections.

pekel = ee.Image('JRC/GSW1_0/GlobalSurfaceWater')

l8 = ee.ImageCollection('LANDSAT/LC08/C01/T1_TOA')
l7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_TOA')
l5 = ee.ImageCollection('LANDSAT/LT05/C01/T1_TOA').map(addPan)

#Identify toa for use in sourced functions.

collection = 'TOA'

#Standardize band names between the various collections and aggregate 
#them into one image collection

bn8 = ['B2','B3', 'B4', 'B5', 'B6','B7', 'B8', 'BQA']
bn57 = ['B1', 'B2', 'B3', 'B4', 'B5','B7', 'B8', 'BQA']
bns = ['Blue', 'Green', 'Red', 'Nir', 'Swir1', 'Swir2', 'Pan', 'qa']
  
ls5 = l5.select(bn57, bns)
ls7 = l7.select(bn57, bns)
ls8 = l8.select(bn8, bns)

ls = ee.ImageCollection(ls5.merge(ls7).merge(ls8))

#Selct the occurence layer in the pekel mask, which is just the 
#percentage of water occurence over a given pixel from 1985-2015.
#Set the percent occurance threshold and create a watermask from the result.
threshold = 80
water = pekel.select('occurrence').gt(threshold)
water = water.updateMask(water)

## Set buffer distance of pixels to include in median calculation.  Distance is in meters from supplied sample point.  
dist = 120

## Identify folder with in-situ data broken up into 5000 observation chunks by path/row and
ULdir = '2_rsdata/out/SplitWide/'


#Generate file lists for both files to be sent and files already processed in google earth engine
filesDown = r.filesDownR['name']
filesUp = os.listdir(ULdir) 

#Remove hidden formatting file in directory and any file names in filesUp that are already in files down.
filesUp  = filter(lambda x: x  != '.DS_Store', filesUp)
filesDown = [i.replace(".csv", ".feather") for i in filesDown]

filesUpFlt = [x for x in filesUp if x not in filesDown]


#### Wrap it all up in a for loop running through our list of files

for x in range(0,3):#len(filesUpFlt)):

  #Read in our file as a feather data frame
  inv = f.read_dataframe(ULdir + filesUpFlt[x])
  #turn our inventory into a feature collection by assigning 
  #lat longs and a site id.  Do this via list comprehension 
  #(similar to for loop but faster and apparently plays nice with earth engine.)
  invOut = ee.FeatureCollection([ee.Feature(ee.Geometry.Point([inv['long'][i],\
  inv['lat'][i]]),{'SiteID':inv['SiteID'][i], 'Date':inv['Date'][i],'SampDate':inv['SampDate'][i]}) for i in range(0,len(inv))]) 
  
  #Pull out the path/row from the file name
  path = int(filesUpFlt[x].replace('.','_').split('_')[0])
  row = int(filesUpFlt[x].replace('.','_').split('_')[1])
  
  #Filter image collection to path/row  
  lsover = ee.ImageCollection(ls.filter(ee.Filter.eq('WRS_PATH',\
  path)).filter(ee.Filter.eq('WRS_ROW', row)))
    
  ## Map over sites within specific path row
  data = ee.FeatureCollection(invOut.map(sitePull))
  
  #Extract path/row count Variable so names match up with file sent to GGE
  if filesUpFlt[x].replace('.','_').split('_')[2] == 'feather':
    count = ''
  else:
    count = '_'+str(int(filesUpFlt[x].replace('.','_').split('_')[2]))
  
  if sat == 'SR':
    dataOut = ee.batch.Export.table.toDrive(collection = data, \
                                                 description = str(path)\
                                                 +'_'+str(row) + count,\
                                                folder = 'WQP_SR_MatchUps',\
                                                fileFormat = 'csv')
  else:
    dataOut = ee.batch.Export.table.toDrive(collection = data, \
                                                description = str(path)\
                                                 +'_'+str(row) + count,\
                                                folder = 'WQP_TOA_MatchUps',\
                                                fileFormat = 'csv')
  maximum_no_of_tasks(15, 60)
  dataOut.start()
```